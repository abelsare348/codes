{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/uYwg5Em2Kkqloh2+A2qi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abelsare348/codes/blob/pyspark/Office/2024_09_23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiMCnynHNxcv",
        "outputId": "e74b8f48-8975-4bd9-fb70-8a8103300cb6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=353d7c61735ab4ebc8de75027783b55f24a97cb8a71d202fd45160274ff67732\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "zNEe9q5vN0ju"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark=SparkSession.builder.appName('spark_json').getOrCreate()"
      ],
      "metadata": {
        "id": "-xDvYXMWN6Vd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W_L4UekYNKrw"
      },
      "outputs": [],
      "source": [
        "anpr_df=spark.read.format(\"json\") \\\n",
        "          .option(\"multiLine\", True) \\\n",
        "          .option(\"header\",True) \\\n",
        "          .option(\"inferschema\",True) \\\n",
        "          .load(\"/content/20240825T0000_Axis_ANPR.json\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode, col\n",
        "\n",
        "# Explode the array column `Data Axis_ANPR`\n",
        "df_exploded = anpr_df.withColumn(\"exploded_ANPR\", explode(col(\"Data Axis_ANPR\")))\n",
        "\n",
        "# Access the nested fields in the exploded struct\n",
        "anpr_df_flattened = df_exploded.select(\n",
        "    col(\"exploded_ANPR.events.currentTimestampUs\").alias(\"currentTimestampUs\"),\n",
        "    col(\"exploded_ANPR.events.vcount.direction.in\").alias(\"direction_in\"),\n",
        "    col(\"exploded_ANPR.events.vcount.direction.out\").alias(\"direction_out\"),\n",
        "    col(\"exploded_ANPR.events.vcount.direction.unk\").alias(\"direction_unk\"),\n",
        "    col(\"exploded_ANPR.events.vcount.list.blocklist\").alias(\"blocklist\"),\n",
        "    col(\"exploded_ANPR.events.vcount.list.allowlist\").alias(\"allowlist\"),\n",
        "    col(\"exploded_ANPR.events.vcount.list.customlist\").alias(\"customlist\"),\n",
        "    col(\"exploded_ANPR.events.vcount.list.nonelist\").alias(\"nonelist\"),\n",
        "    col(\"exploded_ANPR.events.vcount.roi.roi1\").alias(\"roi1\"),\n",
        "    col(\"exploded_ANPR.events.vcount.roi.roi2\").alias(\"roi2\"),\n",
        "    col(\"exploded_ANPR.events.vcount.total\").alias(\"total\")\n",
        ")\n",
        "\n",
        "# Show the flattened DataFrame\n",
        "anpr_df_flattened.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8U3mNpJOsnD",
        "outputId": "10f9dca0-0863-4bb9-98d7-5811efe8c342"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+------------+-------------+-------------+---------+---------+----------+--------+----+----+-----+\n",
            "|currentTimestampUs|direction_in|direction_out|direction_unk|blocklist|allowlist|customlist|nonelist|roi1|roi2|total|\n",
            "+------------------+------------+-------------+-------------+---------+---------+----------+--------+----+----+-----+\n",
            "|1724536805978920  |0           |0            |0            |0        |0        |0         |0       |0   |0   |0    |\n",
            "|1724536816287082  |0           |0            |0            |0        |0        |0         |0       |0   |0   |0    |\n",
            "|1724536826685860  |0           |0            |0            |0        |0        |0         |0       |0   |0   |0    |\n",
            "|1724536837306731  |0           |0            |0            |0        |0        |0         |0       |0   |0   |0    |\n",
            "|1724536847957683  |0           |0            |0            |0        |0        |0         |0       |0   |0   |0    |\n",
            "|1724536858725779  |0           |0            |0            |0        |0        |0         |0       |0   |0   |0    |\n",
            "+------------------+------------+-------------+-------------+---------+---------+----------+--------+----+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, from_unixtime, to_utc_timestamp, from_utc_timestamp"
      ],
      "metadata": {
        "id": "-WiJcEatUOwQ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anpr_df_final= anpr_df_flattened.withColumn(\"currentTimestampUs\",\n",
        "                                            from_unixtime(col(\"currentTimestampUs\") / 1000000))\n",
        "\n",
        "# Remove timezone from cam1_df_a\n",
        "anpr_df_final = anpr_df_final.withColumn(\n",
        "    \"currentTimestampUs\",\n",
        "    from_utc_timestamp(col(\"currentTimestampUs\"), \"UTC+02:00\")\n",
        ")"
      ],
      "metadata": {
        "id": "t9FRTQdVR4kv"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anpr_df_final.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At_JBQfkUbwl",
        "outputId": "bd4a26be-e3e1-40ec-d988-062e755435e2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+------------+-------------+-------------+---------+---------+----------+--------+----+----+-----+\n",
            "| currentTimestampUs|direction_in|direction_out|direction_unk|blocklist|allowlist|customlist|nonelist|roi1|roi2|total|\n",
            "+-------------------+------------+-------------+-------------+---------+---------+----------+--------+----+----+-----+\n",
            "|2024-08-25 00:00:05|           0|            0|            0|        0|        0|         0|       0|   0|   0|    0|\n",
            "|2024-08-25 00:00:16|           0|            0|            0|        0|        0|         0|       0|   0|   0|    0|\n",
            "|2024-08-25 00:00:26|           0|            0|            0|        0|        0|         0|       0|   0|   0|    0|\n",
            "|2024-08-25 00:00:37|           0|            0|            0|        0|        0|         0|       0|   0|   0|    0|\n",
            "|2024-08-25 00:00:47|           0|            0|            0|        0|        0|         0|       0|   0|   0|    0|\n",
            "|2024-08-25 00:00:58|           0|            0|            0|        0|        0|         0|       0|   0|   0|    0|\n",
            "+-------------------+------------+-------------+-------------+---------+---------+----------+--------+----+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DBA_df=spark.read.format(\"json\") \\\n",
        "          .option(\"multiLine\", True) \\\n",
        "          .option(\"header\",True) \\\n",
        "          .option(\"inferschema\",True) \\\n",
        "          .load(\"/content/20240825T0000_DBA data.json\")"
      ],
      "metadata": {
        "id": "xEH5KWrIO51J"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode, col\n",
        "\n",
        "# Explode the outermost array `Data DBA data`\n",
        "df_exploded_1 = DBA_df.withColumn(\"exploded_DBA_data\", explode(col(\"Data DBA data\")))\n",
        "\n",
        "# Explode the inner array inside `exploded_DBA_data`\n",
        "df_exploded_2 = df_exploded_1.withColumn(\"exploded_element\", explode(col(\"exploded_DBA_data\")))\n",
        "\n",
        "# Select the fields from the exploded structure\n",
        "df_flattened = df_exploded_2.select(\n",
        "    col(\"exploded_element.id\").alias(\"id\"),\n",
        "    col(\"exploded_element.resultType\").alias(\"resultType\"),\n",
        "    col(\"exploded_element.timestamp\").alias(\"timestamp\"),\n",
        "    col(\"exploded_element.locations\").alias(\"locations\"),\n",
        "    col(\"exploded_element.values\").alias(\"values\")\n",
        ")\n",
        "\n",
        "# To further explode the `locations` array\n",
        "df_locations_exploded = df_flattened.withColumn(\"exploded_locations\", explode(col(\"locations\")))\n",
        "\n",
        "# Select the individual x, y, z values from the exploded locations\n",
        "DBA_df_final = df_locations_exploded.select(\n",
        "    col(\"id\"),\n",
        "    col(\"resultType\"),\n",
        "    col(\"timestamp\"),\n",
        "    col(\"exploded_locations.x\").alias(\"location_x\"),\n",
        "    col(\"exploded_locations.y\").alias(\"location_y\"),\n",
        "    col(\"exploded_locations.z\").alias(\"location_z\"),\n",
        "    col(\"values\").alias(\"values\")\n",
        ")\n",
        "\n",
        "# Show the final flattened DataFrame\n",
        "DBA_df_final.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWBxuBK0OXtE",
        "outputId": "4ed8dfbd-aec7-4fab-e9a2-fe50a26e2595"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+-----------------------------------+-----------------+-----------------+-----------------+--------------------+\n",
            "|id |resultType|timestamp                          |location_x       |location_y       |location_z       |values              |\n",
            "+---+----------+-----------------------------------+-----------------+-----------------+-----------------+--------------------+\n",
            "|1  |Event     |2024-08-25T00:00:43.536273587+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[46.830772399902344]|\n",
            "|1  |Event     |2024-08-25T00:00:43.536273535+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[46.830772399902344]|\n",
            "|1  |Event     |2024-08-25T00:00:51.063551509+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[48.511775970458984]|\n",
            "|1  |Event     |2024-08-25T00:00:51.175898729+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[48.94055938720703] |\n",
            "|1  |Event     |2024-08-25T00:00:51.288246159+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[48.128929138183594]|\n",
            "|1  |Event     |2024-08-25T00:00:51.512941015+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[46.17887496948242] |\n",
            "|1  |Event     |2024-08-25T00:00:51.737635924+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[49.649959564208984]|\n",
            "|1  |Event     |2024-08-25T00:00:51.849983301+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[49.17671203613281] |\n",
            "|1  |Event     |2024-08-25T00:00:51.962330677+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[47.637664794921875]|\n",
            "|1  |Event     |2024-08-25T00:00:52.074678158+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[52.57440185546875] |\n",
            "|1  |Event     |2024-08-25T00:00:52.524067872+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[47.71942901611328] |\n",
            "|1  |Event     |2024-08-25T00:00:52.748762730+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[45.39942932128906] |\n",
            "|1  |Event     |2024-08-25T00:00:53.198152392+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[50.56135559082031] |\n",
            "|1  |Event     |2024-08-25T00:00:53.310499873+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[47.08549880981445] |\n",
            "|1  |Event     |2024-08-25T00:00:53.422847301+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[47.01286697387695] |\n",
            "|1  |Event     |2024-08-25T00:00:53.535194730+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[49.78752899169922] |\n",
            "|1  |Event     |2024-08-25T00:00:53.872237015+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[45.25800704956055] |\n",
            "|1  |Event     |2024-08-25T00:00:54.096931925+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[50.76137161254883] |\n",
            "|1  |Event     |2024-08-25T00:00:54.209279301+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[48.25901412963867] |\n",
            "|1  |Event     |2024-08-25T00:00:54.433974158+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[47.45514678955078] |\n",
            "+---+----------+-----------------------------------+-----------------+-----------------+-----------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DBC_df=spark.read.format(\"json\") \\\n",
        "          .option(\"multiLine\", True) \\\n",
        "          .option(\"header\",True) \\\n",
        "          .option(\"inferschema\",True) \\\n",
        "          .load(\"/content/20240825T0000_DBC data.json\")"
      ],
      "metadata": {
        "id": "z1VK0WFsPVI_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode, col\n",
        "\n",
        "# First explode the outer array `Data DBC data`\n",
        "df_exploded_1 = DBC_df.withColumn(\"exploded_DBC_data\", explode(col(\"Data DBC data\")))\n",
        "\n",
        "# Second explode the inner array within `Data DBC data`\n",
        "df_exploded_2 = df_exploded_1.withColumn(\"exploded_element\", explode(col(\"exploded_DBC_data\")))\n",
        "\n",
        "# Select the fields from the exploded struct\n",
        "df_flattened = df_exploded_2.select(\n",
        "    col(\"exploded_element.id\").alias(\"id\"),\n",
        "    col(\"exploded_element.resultType\").alias(\"resultType\"),\n",
        "    col(\"exploded_element.timestamp\").alias(\"timestamp\"),\n",
        "    col(\"exploded_element.locations\").alias(\"locations\"),\n",
        "    col(\"exploded_element.values\").alias(\"values\")\n",
        ")\n",
        "\n",
        "# Explode the `locations` array to access `x`, `y`, and `z`\n",
        "df_locations_exploded = df_flattened.withColumn(\"exploded_locations\", explode(col(\"locations\")))\n",
        "\n",
        "# Select the individual x, y, z values from the exploded locations\n",
        "DBC_df_final = df_locations_exploded.select(\n",
        "    col(\"id\"),\n",
        "    col(\"resultType\"),\n",
        "    col(\"timestamp\"),\n",
        "    col(\"exploded_locations.x\").alias(\"location_x\"),\n",
        "    col(\"exploded_locations.y\").alias(\"location_y\"),\n",
        "    col(\"exploded_locations.z\").alias(\"location_z\"),\n",
        "    col(\"values\").alias(\"values\")\n",
        ")\n",
        "\n",
        "# Show the final flattened DataFrame\n",
        "DBC_df_final.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoqQ34FhPqvm",
        "outputId": "16f96bfe-346c-4d35-ccf5-862a9c405a68"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+-----------------------------------+-----------------+-----------------+-----------------+--------------------+\n",
            "|id |resultType|timestamp                          |location_x       |location_y       |location_z       |values              |\n",
            "+---+----------+-----------------------------------+-----------------+-----------------+-----------------+--------------------+\n",
            "|2  |Event     |2024-08-24T23:59:34.966892963+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[51.28324508666992] |\n",
            "|2  |Event     |2024-08-24T23:59:35.079240601+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[51.395042419433594]|\n",
            "|2  |Event     |2024-08-24T23:59:35.191587873+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[50.98021697998047] |\n",
            "|2  |Event     |2024-08-24T23:59:35.303935353+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[51.33732223510742] |\n",
            "|2  |Event     |2024-08-24T23:59:35.416282729+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[51.0670280456543]  |\n",
            "|2  |Event     |2024-08-24T23:59:35.528630106+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[51.51207733154297] |\n",
            "|2  |Event     |2024-08-24T23:59:35.640977587+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[51.784027099609375]|\n",
            "|2  |Event     |2024-08-24T23:59:35.753325015+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[52.06098937988281] |\n",
            "|2  |Event     |2024-08-24T23:59:35.865672444+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[51.86702346801758] |\n",
            "|2  |Event     |2024-08-24T23:59:35.978019873+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[51.712303161621094]|\n",
            "|2  |Event     |2024-08-24T23:59:36.090367249+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[51.45716094970703] |\n",
            "|2  |Event     |2024-08-24T23:59:36.202714729+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[51.82398986816406] |\n",
            "|2  |Event     |2024-08-24T23:59:36.315062158+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[51.53913116455078] |\n",
            "|2  |Event     |2024-08-24T23:59:36.427409587+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[51.76115417480469] |\n",
            "|2  |Event     |2024-08-24T23:59:36.539757015+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[51.68079376220703] |\n",
            "|2  |Event     |2024-08-24T23:59:36.652104444+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[51.75293731689453] |\n",
            "|2  |Event     |2024-08-24T23:59:36.764451872+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[52.131370544433594]|\n",
            "|2  |Event     |2024-08-24T23:59:36.876799353+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[51.78373336791992] |\n",
            "|2  |Event     |2024-08-24T23:59:36.989146730+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[51.574012756347656]|\n",
            "|2  |Event     |2024-08-24T23:59:37.101494106+02:00|4320424.244834278|565871.5884135148|4642458.985721508|[51.570648193359375]|\n",
            "+---+----------+-----------------------------------+-----------------+-----------------+-----------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "anpr_df_final = anpr_df_final.withColumn(\n",
        "    \"currentTimestampUs\",\n",
        "    to_utc_timestamp(col(\"currentTimestampUs\"), \"UTC\")\n",
        ")\n",
        "\n",
        "# Remove timezone from cam2_df_d\n",
        "DBA_df_final = DBA_df_final.withColumn(\n",
        "    \"timestamp\",\n",
        "    to_utc_timestamp(col(\"timestamp\"), \"UTC\")\n",
        ")"
      ],
      "metadata": {
        "id": "-b9CQ7LeVl-L"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, abs, unix_timestamp,expr\n",
        "\n",
        "# Convert the timestamps to unix timestamps (seconds since epoch) for comparison\n",
        "df_a = anpr_df_final\n",
        "df_d = DBA_df_final\n",
        "\n",
        "# Perform a cross join between the two DataFrames (this is needed since we're doing an asof join)\n",
        "cross_joined_df = df_a.join(df_d, df_a[\"currentTimestampUs\"] >= df_d[\"timestamp\"], \"left_outer\")\n",
        "\n",
        "# Calculate the absolute difference between the timestamps\n",
        "cross_joined_df = cross_joined_df.withColumn(\"time_diff\",\n",
        "                                             abs(col(\"currentTimestampUs\") - col(\"timestamp\")))\n",
        "\n",
        "# Filter out rows where the time difference is greater than 3 hours (10800 seconds)\n",
        "filtered_df = cross_joined_df.filter(expr(\"time_diff <= interval 10800 seconds\"))\n",
        "\n",
        "# Use windowing to get the nearest match within the 3-hour tolerance\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import row_number\n",
        "\n",
        "# Window partitioned by events.currentTimestampUs and ordered by the time_diff\n",
        "window_spec = Window.partitionBy(\"currentTimestampUs\").orderBy(col(\"time_diff\"))\n",
        "\n",
        "# Add a row number and filter to keep only the first row (the nearest match)\n",
        "final_df = filtered_df.withColumn(\"rn\", row_number().over(window_spec)).filter(col(\"rn\") == 1)\n",
        "\n",
        "# Drop the auxiliary columns if no longer needed\n",
        "final_df = final_df.drop(\"time_diff\", \"rn\")"
      ],
      "metadata": {
        "id": "6H9kqzrgSPkA"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlAQiwOeZQ3U",
        "outputId": "76120115-f2e6-4f95-f41d-b8cd1f527ff6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+------------+-------------+-------------+---------+---------+----------+--------+----+----+-----+---+----------+--------------------+-----------------+-----------------+-----------------+-------------------+\n",
            "| currentTimestampUs|direction_in|direction_out|direction_unk|blocklist|allowlist|customlist|nonelist|roi1|roi2|total| id|resultType|           timestamp|       location_x|       location_y|       location_z|             values|\n",
            "+-------------------+------------+-------------+-------------+---------+---------+----------+--------+----+----+-----+---+----------+--------------------+-----------------+-----------------+-----------------+-------------------+\n",
            "|2024-08-25 00:00:05|           0|            0|            0|        0|        0|         0|       0|   0|   0|    0|  1|     Event|2024-08-24 22:00:...|4320424.244834278|565871.5884135148|4642458.985721508|[48.01514434814453]|\n",
            "|2024-08-25 00:00:16|           0|            0|            0|        0|        0|         0|       0|   0|   0|    0|  1|     Event|2024-08-24 22:00:...|4320424.244834278|565871.5884135148|4642458.985721508|[48.01514434814453]|\n",
            "|2024-08-25 00:00:26|           0|            0|            0|        0|        0|         0|       0|   0|   0|    0|  1|     Event|2024-08-24 22:00:...|4320424.244834278|565871.5884135148|4642458.985721508|[48.01514434814453]|\n",
            "|2024-08-25 00:00:37|           0|            0|            0|        0|        0|         0|       0|   0|   0|    0|  1|     Event|2024-08-24 22:00:...|4320424.244834278|565871.5884135148|4642458.985721508|[48.01514434814453]|\n",
            "|2024-08-25 00:00:47|           0|            0|            0|        0|        0|         0|       0|   0|   0|    0|  1|     Event|2024-08-24 22:00:...|4320424.244834278|565871.5884135148|4642458.985721508|[48.01514434814453]|\n",
            "|2024-08-25 00:00:58|           0|            0|            0|        0|        0|         0|       0|   0|   0|    0|  1|     Event|2024-08-24 22:00:...|4320424.244834278|565871.5884135148|4642458.985721508|[48.01514434814453]|\n",
            "+-------------------+------------+-------------+-------------+---------+---------+----------+--------+----+----+-----+---+----------+--------------------+-----------------+-----------------+-----------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}